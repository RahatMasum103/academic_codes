{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 7: Naive Bayes and K-NN classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In this lab we will work with a subset of the 20 newsgroup data that was mentioned during the Naive Bayes discussion in class. We will select only four of 10 newsgroups to work with. \n",
    "\n",
    "##### First we load the data and take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.med', 'sci.space', 'soc.religion.christian'] \n",
      "\n",
      "6 rec.sport.hockey\n",
      "6 soc.religion.christian\n",
      "2 misc.forsale\n",
      "0 rec.sport.baseball\n",
      "5 sci.space\n",
      "6 alt.atheism\n",
      "6 rec.sport.hockey\n",
      "2 misc.forsale\n",
      "0 rec.sport.baseball\n",
      "6 rec.sport.hockey\n",
      "6 soc.religion.christian\n",
      "8 rec.motorcycles\n",
      "9 comp.graphics\n",
      "6 rec.sport.hockey\n",
      "0 rec.sport.baseball\n",
      "5 sci.space\n",
      "2 misc.forsale\n",
      "9 comp.graphics\n",
      "0 rec.sport.baseball\n",
      "0 rec.sport.baseball\n",
      "9 comp.graphics\n",
      "5 rec.autos\n",
      "5 rec.autos\n",
      "6 soc.religion.christian\n",
      "9 comp.graphics\n",
      "\n",
      " [\"From: huot@cray.com (Tom Huot)\\nSubject: Re: Ulf and all...\\nLines: 29\\nNntp-Posting-Host: pittpa.cray.com\\nOrganization: Cray Research Inc.\\nX-Newsreader: TIN [version 1.1 PL8]\\n\\nRichard Wernick (richard@amc.com) wrote:\\n: You should be ashamed to call yourself an Ulf Samuelson fan. Anybody who plays\\n: the way he does, does not belong in the NHL. There have been cheap shot artists\\n: through the history of the game, but a lot of them have been talanted players.\\n: Bobby Clarke, Kenny Linsemen, Pie McKenzie, Chris Chelios etc.. but nobody has been\\n: out right as dirty a cheapshot coward as Ulf. Violence in hockey has got to be curbed\\n: and players like (Should have been a Women) Samuelson don't belong. When players\\n: like Ulf, who's main purpose is to injure the better players in the league is allowed\\n: to continue, and the league won't stop it, the players should. A Christian Pro 1000\\n: aluminum stick directed at his ugly head should do the trick nicely. If the Bruins get\\n: a chance to meet Pittsburgh in the near future, you can bet Neely will have his day.\\n: The sight of watching Ulf turtle up like the coward he is, is worth almost as much as a\\n: Stanely Cup. This wimp of a player almost ruined the career of one the best right wingers\\n: in the game. If you are to remove Ulf Samuelson from the lineup, the Penguins would not\\n: even notice he's gone. He's an eyesore on the game of hockey.\\n\\n\\n: Rich\\n\\n\\nThank you for your extremely lucid and well thought out observation.\\nNow when you get back on your medication, please let us know how you\\nare feeling. \\nThank you,\\n--\\n_____________________________________________________________________________\\nTom Huot        \\t\\t\\t       \\nhuot@cray.com \\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\"]\n"
     ]
    }
   ],
   "source": [
    "# load training data\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med', 'sci.space',\n",
    "              'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey']\n",
    "\n",
    "# read the data in twenty_train.data and twenty_train.target\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "# print the class names\n",
    "print (twenty_train.target_names, \"\\n\")\n",
    "\n",
    "# print the class names for the first 25 articles\n",
    "for t in twenty_train.target[:25]:\n",
    "    print(twenty_train.target[t], twenty_train.target_names[t])\n",
    "    \n",
    "# print the first article\n",
    "print(\"\\n\", twenty_train.data[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert the data to word counts and see how many times the word 'algorithm' appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10285"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import and use CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data) \n",
    "\n",
    "count_vect.vocabulary_.get(u'algorithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.922342621259\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.91      0.87      0.89       319\n",
      "         comp.graphics       0.90      0.91      0.90       389\n",
      "          misc.forsale       0.95      0.85      0.90       390\n",
      "             rec.autos       0.87      0.95      0.91       396\n",
      "       rec.motorcycles       0.97      0.95      0.96       398\n",
      "    rec.sport.baseball       0.97      0.93      0.95       397\n",
      "      rec.sport.hockey       0.95      0.97      0.96       399\n",
      "               sci.med       0.95      0.86      0.90       396\n",
      "             sci.space       0.92      0.94      0.93       394\n",
      "soc.religion.christian       0.87      0.97      0.92       398\n",
      "\n",
      "           avg / total       0.92      0.92      0.92      3876\n",
      "\n",
      "[[276   1   1   2   1   1   2   2   3  30]\n",
      " [  5 354   2   5   0   2   2   5  11   3]\n",
      " [  0  16 333  24   2   1   3   4   6   1]\n",
      " [  0   2   6 378   3   1   2   0   4   0]\n",
      " [  0   0   3  12 380   0   0   0   1   2]\n",
      " [  3   1   2   6   0 370  11   0   3   1]\n",
      " [  0   0   0   1   0   5 387   1   1   4]\n",
      " [ 10   9   4   4   7   3   1 342   3  13]\n",
      " [  6   9   1   1   0   0   0   4 369   4]\n",
      " [  4   2   0   0   0   0   1   3   2 386]]\n"
     ]
    }
   ],
   "source": [
    "# Import Multinomial NB (this a good Naive Bayes classifier for text) and other libraries to help with analysis\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "# fit classifier using word counts\n",
    "clf_1 = MultinomialNB().fit(X_train_counts, twenty_train.target)\n",
    "\n",
    "# load the test data set and convert to word counts\n",
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "# note that I am using .transform instead of .fit_transform. this keeps the columns the same as the training set\n",
    "X_test_counts = count_vect.transform(twenty_test.data)\n",
    "\n",
    "# make predictions on test data\n",
    "predicted = clf_1.predict(X_test_counts)\n",
    "\n",
    "# print accuracy\n",
    "print (np.mean(predicted == twenty_test.target)) \n",
    "\n",
    "# print precision and recall statistics\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))\n",
    "\n",
    "# print confusion matrix\n",
    "print(metrics.confusion_matrix(twenty_test.target, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert the data to a TF-IDF representation and run Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.868937048504\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.97      0.55      0.70       319\n",
      "         comp.graphics       0.93      0.83      0.88       389\n",
      "          misc.forsale       0.96      0.83      0.89       390\n",
      "             rec.autos       0.88      0.94      0.91       396\n",
      "       rec.motorcycles       0.94      0.94      0.94       398\n",
      "    rec.sport.baseball       0.94      0.90      0.92       397\n",
      "      rec.sport.hockey       0.92      0.97      0.94       399\n",
      "               sci.med       0.94      0.77      0.85       396\n",
      "             sci.space       0.92      0.91      0.91       394\n",
      "soc.religion.christian       0.58      0.98      0.73       398\n",
      "\n",
      "           avg / total       0.90      0.87      0.87      3876\n",
      "\n",
      "[[175   1   0   0   2   1   1   6   3 130]\n",
      " [  1 322   2   9   3   7   2   1  10  32]\n",
      " [  0  10 322  20   5   4   5   6   4  14]\n",
      " [  0   3   5 373   3   2   3   1   3   3]\n",
      " [  0   0   2  12 375   0   0   0   0   9]\n",
      " [  0   0   1   4   0 358  21   0   2  11]\n",
      " [  0   0   0   1   0   4 388   0   1   5]\n",
      " [  2   6   3   1   7   5   3 305   7  57]\n",
      " [  0   4   0   2   1   0   1   4 360  22]\n",
      " [  2   1   0   0   1   0   0   1   3 390]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "clf_2 = MultinomialNB().fit(X_train_tfidf, twenty_train.target)\n",
    "\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "# make predictions on test data\n",
    "predicted = clf_2.predict(X_test_tfidf)\n",
    "\n",
    "# print accuracy\n",
    "print (np.mean(predicted == twenty_test.target)) \n",
    "\n",
    "# print precision and recall statistics\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))\n",
    "\n",
    "# print confusion matrix\n",
    "print(metrics.confusion_matrix(twenty_test.target, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a pipeline for Naive Bayes for TF-IDF and rerun experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.868937048504\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.97      0.55      0.70       319\n",
      "         comp.graphics       0.93      0.83      0.88       389\n",
      "          misc.forsale       0.96      0.83      0.89       390\n",
      "             rec.autos       0.88      0.94      0.91       396\n",
      "       rec.motorcycles       0.94      0.94      0.94       398\n",
      "    rec.sport.baseball       0.94      0.90      0.92       397\n",
      "      rec.sport.hockey       0.92      0.97      0.94       399\n",
      "               sci.med       0.94      0.77      0.85       396\n",
      "             sci.space       0.92      0.91      0.91       394\n",
      "soc.religion.christian       0.58      0.98      0.73       398\n",
      "\n",
      "           avg / total       0.90      0.87      0.87      3876\n",
      "\n",
      "[[175   1   0   0   2   1   1   6   3 130]\n",
      " [  1 322   2   9   3   7   2   1  10  32]\n",
      " [  0  10 322  20   5   4   5   6   4  14]\n",
      " [  0   3   5 373   3   2   3   1   3   3]\n",
      " [  0   0   2  12 375   0   0   0   0   9]\n",
      " [  0   0   1   4   0 358  21   0   2  11]\n",
      " [  0   0   0   1   0   4 388   0   1   5]\n",
      " [  2   6   3   1   7   5   3 305   7  57]\n",
      " [  0   4   0   2   1   0   1   4 360  22]\n",
      " [  2   1   0   0   1   0   0   1   3 390]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "clf_3 = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "clf_3.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "# make predictions on test data\n",
    "predicted = clf_3.predict(twenty_test.data)\n",
    "\n",
    "# print accuracy\n",
    "print (np.mean(predicted == twenty_test.target)) \n",
    "\n",
    "# print precision and recall statistics\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))\n",
    "\n",
    "# print confusion matrix\n",
    "print(metrics.confusion_matrix(twenty_test.target, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a pipeline for Naive Bayes for word_counts and rerun experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.922342621259\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.91      0.87      0.89       319\n",
      "         comp.graphics       0.90      0.91      0.90       389\n",
      "          misc.forsale       0.95      0.85      0.90       390\n",
      "             rec.autos       0.87      0.95      0.91       396\n",
      "       rec.motorcycles       0.97      0.95      0.96       398\n",
      "    rec.sport.baseball       0.97      0.93      0.95       397\n",
      "      rec.sport.hockey       0.95      0.97      0.96       399\n",
      "               sci.med       0.95      0.86      0.90       396\n",
      "             sci.space       0.92      0.94      0.93       394\n",
      "soc.religion.christian       0.87      0.97      0.92       398\n",
      "\n",
      "           avg / total       0.92      0.92      0.92      3876\n",
      "\n",
      "[[276   1   1   2   1   1   2   2   3  30]\n",
      " [  5 354   2   5   0   2   2   5  11   3]\n",
      " [  0  16 333  24   2   1   3   4   6   1]\n",
      " [  0   2   6 378   3   1   2   0   4   0]\n",
      " [  0   0   3  12 380   0   0   0   1   2]\n",
      " [  3   1   2   6   0 370  11   0   3   1]\n",
      " [  0   0   0   1   0   5 387   1   1   4]\n",
      " [ 10   9   4   4   7   3   1 342   3  13]\n",
      " [  6   9   1   1   0   0   0   4 369   4]\n",
      " [  4   2   0   0   0   0   1   3   2 386]]\n",
      "\n",
      " 5824\n",
      "\n",
      "[samples,features] (5824, 62475)\n"
     ]
    }
   ],
   "source": [
    "# insert code here\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "clf_4 = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('clf', MultinomialNB()),                 \n",
    "])\n",
    "\n",
    "clf_4.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "# make predictions on test data\n",
    "predicted = clf_4.predict(twenty_test.data)\n",
    "\n",
    "# print accuracy\n",
    "print (np.mean(predicted == twenty_test.target)) \n",
    "\n",
    "# print precision and recall statistics\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))\n",
    "\n",
    "# print confusion matrix\n",
    "print(metrics.confusion_matrix(twenty_test.target, predicted))\n",
    "\n",
    "print ('\\n',len(twenty_train.data))\n",
    "print ('\\n[samples,features]',X_train_counts.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create and test a nearest-neighbor classfier using word counts and 5 neighbors (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.453818369453\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.46      0.53      0.49       319\n",
      "         comp.graphics       0.25      0.50      0.34       389\n",
      "          misc.forsale       0.72      0.48      0.58       390\n",
      "             rec.autos       0.35      0.40      0.37       396\n",
      "       rec.motorcycles       0.74      0.49      0.59       398\n",
      "    rec.sport.baseball       0.46      0.36      0.40       397\n",
      "      rec.sport.hockey       0.50      0.52      0.51       399\n",
      "               sci.med       0.53      0.26      0.35       396\n",
      "             sci.space       0.84      0.36      0.50       394\n",
      "soc.religion.christian       0.38      0.66      0.48       398\n",
      "\n",
      "           avg / total       0.53      0.45      0.46      3876\n",
      "\n",
      "[[168  23   6  16   4  13   9   9   2  69]\n",
      " [ 19 195  15  36   8  15  20   7   8  66]\n",
      " [  6 125 187  22   3   6  12   4   1  24]\n",
      " [ 19  75   9 158  14  28  29  15   3  46]\n",
      " [ 11  47   9  48 195  15  22  11   0  40]\n",
      " [ 32  70   9  34   8 141  46  11   4  42]\n",
      " [ 12  52   5  32   7  49 207   2   1  32]\n",
      " [ 29  86  11  50  12  13  22 103   4  66]\n",
      " [ 25  64   6  30  10  15  31  21 141  51]\n",
      " [ 42  32   1  21   2   9  12  12   3 264]]\n"
     ]
    }
   ],
   "source": [
    "# k-means\n",
    "from sklearn import neighbors\n",
    "\n",
    "clf_5=neighbors.KNeighborsClassifier(n_neighbors = 5) # don't need argument here but do later\n",
    "\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "clf_5.fit(X_train_counts, twenty_train.target)\n",
    "\n",
    "predicted = clf_5.predict(X_test_counts)\n",
    "\n",
    "print (np.mean(predicted == twenty_test.target)) \n",
    "\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))\n",
    "\n",
    "print(metrics.confusion_matrix(twenty_test.target, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create and test a nearest-neighbor classfier using IF-IDF vectors and 5 neighbors (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.764705882353\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.52      0.85      0.64       319\n",
      "         comp.graphics       0.74      0.73      0.73       389\n",
      "          misc.forsale       0.76      0.66      0.71       390\n",
      "             rec.autos       0.80      0.79      0.79       396\n",
      "       rec.motorcycles       0.84      0.83      0.83       398\n",
      "    rec.sport.baseball       0.82      0.78      0.80       397\n",
      "      rec.sport.hockey       0.86      0.88      0.87       399\n",
      "               sci.med       0.89      0.54      0.67       396\n",
      "             sci.space       0.86      0.77      0.81       394\n",
      "soc.religion.christian       0.71      0.84      0.77       398\n",
      "\n",
      "           avg / total       0.78      0.76      0.77      3876\n",
      "\n",
      "[[270   2   5   1   0   1   0   7   5  28]\n",
      " [ 35 285  13  14   9   8   5   3   9   8]\n",
      " [ 11  31 256  17  21  17  10   6  11  10]\n",
      " [ 16  17  15 313  11   6   7   2   2   7]\n",
      " [ 17   3   9  18 329   2   4   2   2  12]\n",
      " [ 27   6   8   8   6 311  16   0   7   8]\n",
      " [ 12   6   5   1   2  11 350   1   1  10]\n",
      " [ 59  14  18  11  12  16   7 212   6  41]\n",
      " [ 33  20   6   8   3   4   3   3 305   9]\n",
      " [ 44   3   1   1   0   2   4   3   7 333]]\n"
     ]
    }
   ],
   "source": [
    "# insert code here\n",
    "\n",
    "from sklearn import neighbors\n",
    "\n",
    "clf_6=neighbors.KNeighborsClassifier(n_neighbors = 5) # don't need argument here but do later\n",
    "\n",
    "#TF-IDF \n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "clf_6.fit(X_train_tfidf, twenty_train.target)\n",
    "\n",
    "predicted = clf_6.predict(X_test_tfidf)\n",
    "\n",
    "print (np.mean(predicted == twenty_test.target)) \n",
    "\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))\n",
    "\n",
    "print(metrics.confusion_matrix(twenty_test.target, predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using TF-IDF vectors, write code that uses cross-validation to select the number of neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected number of neighbours =  1\n"
     ]
    }
   ],
   "source": [
    "# insert code here 1\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# number of folds\n",
    "k = 10\n",
    "\n",
    "X = X_train_tfidf\n",
    "y =  twenty_train.target\n",
    "\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=None)\n",
    "\n",
    "best_rss = float(\"infinity\")\n",
    "for i in range(1,10):\n",
    "    clf_7=neighbors.KNeighborsClassifier(n_neighbors = i)\n",
    "    rss_sum=0\n",
    "\n",
    "    \n",
    "    # compute 10-fold cv RSS\n",
    "    for train_index, test_index in kf.split(X_train_tfidf):\n",
    "        X_tr, X_te = X[train_index], X[test_index]\n",
    "        y_tr, y_te = y[train_index], y[test_index]\n",
    "        clf_7.fit(X_tr,y_tr)\n",
    "        y_pred = clf_7.predict(X_te)\n",
    "        rss = sum((y_pred-y_te)**2)\n",
    "        rss_sum = rss_sum + rss\n",
    "        \n",
    "    if (rss_sum < best_rss):\n",
    "        best_neighbour = i\n",
    "        best_rss = rss_sum\n",
    "        \n",
    "print(\"Selected number of neighbours = \", best_neighbour)\n",
    "# print (y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate the performance of k-nn using the selected number of neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.776315789474\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.64      0.84      0.73       319\n",
      "         comp.graphics       0.71      0.71      0.71       389\n",
      "          misc.forsale       0.76      0.64      0.70       390\n",
      "             rec.autos       0.82      0.75      0.78       396\n",
      "       rec.motorcycles       0.83      0.86      0.84       398\n",
      "    rec.sport.baseball       0.79      0.79      0.79       397\n",
      "      rec.sport.hockey       0.83      0.86      0.85       399\n",
      "               sci.med       0.84      0.67      0.75       396\n",
      "             sci.space       0.82      0.85      0.83       394\n",
      "soc.religion.christian       0.74      0.80      0.77       398\n",
      "\n",
      "           avg / total       0.78      0.78      0.78      3876\n",
      "\n",
      "[[267   3   5   1   3   3   0   8   7  22]\n",
      " [ 17 276  18  15   8   9  10   8  16  12]\n",
      " [  4  31 250  12  17  26  16   5  16  13]\n",
      " [  8  18  16 298  17   7   8  10  11   3]\n",
      " [ 12   8   2  14 341   4   3   7   3   4]\n",
      " [ 13   8   7  10   3 314  19   2   5  16]\n",
      " [  7   8   9   2   1  14 345   3   3   7]\n",
      " [ 28  18  14   4  14  14   5 266   4  29]\n",
      " [ 11  15   5   7   4   3   3   5 333   8]\n",
      " [ 49   4   1   2   4   1   5   3  10 319]]\n"
     ]
    }
   ],
   "source": [
    "# insert code here\n",
    "\n",
    "from sklearn import neighbors\n",
    "\n",
    "clf_8=neighbors.KNeighborsClassifier(n_neighbors = best_neighbour) # don't need argument here but do later\n",
    "\n",
    "#TF-IDF \n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "clf_8.fit(X_train_tfidf, twenty_train.target)\n",
    "\n",
    "predicted = clf_8.predict(X_test_tfidf)\n",
    "\n",
    "print (np.mean(predicted == twenty_test.target)) \n",
    "\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))\n",
    "\n",
    "print(metrics.confusion_matrix(twenty_test.target, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
