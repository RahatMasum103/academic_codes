{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Sampling for evaluation\n",
    "\n",
    "#### We will start by importing numpy, pandas, and matplotlib. (We will import other libraries/packages as we need them.) We will also read our spambase csv file into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spambase loaded.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "spambase = pd.read_csv('spambase.csv')\n",
    "\n",
    "print(\"Spambase loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's build our logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training data: 0.932880434783\n",
      "Score on test data: 0.909880564604\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# first we need to prepare the data\n",
    "\n",
    "# add an intercept column\n",
    "spambase['_intercept'] = 1\n",
    "\n",
    "# Copy spambase across and drop spam_class (we don't include the class feature in the training data)\n",
    "X = spambase\n",
    "X = X.drop('spam_class', axis=1)\n",
    "\n",
    "# Set y as the spam column, we need to wrap it in the dataframe to stop it being series \n",
    "y_df = pd.DataFrame(spambase.spam_class)\n",
    "\n",
    "# flatten y into a 1-D array\n",
    "y = np.ravel(y_df)\n",
    "\n",
    "# now split the data into training data and test data (80/20 split)\n",
    "# random_state = k sets a specific random seed\n",
    "# since random_state is fixed, this call will always produce the same split\n",
    "# if you leave out the random_state value, you will get a different random split when you run it agaimn\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# create our model and fit it to our training data\n",
    "# the large C value essentail turns off regularization (which we will cover later)\n",
    "# ignore it for now\n",
    "logres = LogisticRegression(C = 1e9)\n",
    "logres.fit(X_train,y_train)\n",
    "\n",
    "# let's check our training and test accuracy\n",
    "train_score = logres.score(X_train, y_train)\n",
    "test_score = logres.score(X_test, y_test)\n",
    "\n",
    "print (\"Score on training data:\", train_score)\n",
    "print (\"Score on test data:\", test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the cell below, I have provided code that computes and prints the mean of the training and test errors for ten RANDOM train/test splits. Add code to compute and print the corresponding standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOLDOUT STATS\n",
      "Accuracy: mean =  0.925732899023\n",
      "TPR: mean =  0.891513860428\n",
      "FPR: mean =  0.0522061899326\n",
      "Accuracy: Standard Deviation =  0.0106627437109\n",
      "TPR: Standard Deviation =  0.0176991756029\n",
      "FPR: Standard Deviation =  0.0113587620705\n"
     ]
    }
   ],
   "source": [
    "# compute and print the mean of the training and test errors for ten RANDOM train/test splits\n",
    "\n",
    "# insert code here\n",
    "i = 0\n",
    "total_holdouts = 10\n",
    "acc = np.zeros((total_holdouts))\n",
    "tpr = np.zeros((total_holdouts))\n",
    "fpr = np.zeros((total_holdouts))\n",
    "while (i < total_holdouts):\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    lr = logres.fit(X_tr, y_tr)\n",
    "    \n",
    "    #y_pred = logres.fit(X_tr, y_tr).predict(X_te)\n",
    "    y_pred = lr.predict(X_te)\n",
    "    \n",
    "    # compute confusion matrix\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    j = 0\n",
    "    while (j < len(y_te)):\n",
    "        if (y_pred[j]==y_te[j]):\n",
    "            if (y_te[j]==0): # tn\n",
    "                tn = tn + 1\n",
    "            else: # tp\n",
    "                tp = tp + 1\n",
    "        else:\n",
    "            if (y_te[j]==0): # fp\n",
    "                fp = fp + 1\n",
    "            else: # fn\n",
    "                fn = fn + 1        \n",
    "        j = j + 1\n",
    "    acc[i] = (tp+tn)/j\n",
    "    tpr[i] = tp/(tp+fn)\n",
    "    fpr[i] = fp/(fp+tn)\n",
    "    i = i + 1\n",
    "        \n",
    "# include mean and std dev\n",
    "mean_acc = 0\n",
    "mean_tpr = 0\n",
    "mean_fpr = 0\n",
    "i = 0\n",
    "while (i < total_holdouts):\n",
    "    mean_acc = mean_acc + acc[i]\n",
    "    mean_tpr = mean_tpr + tpr[i]\n",
    "    mean_fpr = mean_fpr + fpr[i]\n",
    "    i = i + 1\n",
    "    \n",
    "mean_acc = mean_acc/total_holdouts\n",
    "mean_tpr = mean_tpr/total_holdouts\n",
    "mean_fpr = mean_fpr/total_holdouts\n",
    "\n",
    "# ADD CODE TO COMPUTE AND PRINT THE STANDARD DEVIATIONS OF THE THREE STATISTICS\n",
    "\n",
    "std_acc = np.std(acc)\n",
    "std_tpr = np.std(tpr)\n",
    "std_fpr = np.std(fpr)\n",
    "\n",
    "\n",
    "print(\"HOLDOUT STATS\")\n",
    "print(\"Accuracy: mean = \",mean_acc)\n",
    "print(\"TPR: mean = \",mean_tpr)\n",
    "print(\"FPR: mean = \",mean_fpr)\n",
    "\n",
    "\n",
    "print (\"Accuracy: Standard Deviation = \", std_acc)\n",
    "print (\"TPR: Standard Deviation = \", std_tpr)\n",
    "print (\"FPR: Standard Deviation = \", std_fpr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bootstrap: In cell below, I have provided code that computes the average performance across b bootstrap samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of instances in test data =  0.36209519669637036\n",
      "Fraction of instances in test data =  0.3668767659204521\n",
      "Fraction of instances in test data =  0.36405129319713103\n",
      "Fraction of instances in test data =  0.3644859813084112\n",
      "Fraction of instances in test data =  0.36405129319713103\n",
      "BOOTSTRAP STATS\n",
      "Accuracy =  0.9276823331147984\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# average performance across b=5 bootstrap samples\n",
    "total_bootstraps = 5\n",
    "\n",
    "bootstrap_size = len(y)\n",
    "\n",
    "i = 0\n",
    "bootstrap_idx = np.zeros((bootstrap_size+1))\n",
    "acc = 0\n",
    "while (i < total_bootstraps):\n",
    "    # create bootstrap training and set\n",
    "    j = 0\n",
    "    while (j < bootstrap_size): \n",
    "        bootstrap_idx[j] = random.randint(0,bootstrap_size-1)\n",
    "        j = j + 1\n",
    "    bootstrap_idx[j] = j # add value to enable stopping duribng bootstrap creation\n",
    "    \n",
    "    bootstrap_idx.sort()\n",
    "    \n",
    "    j = 0\n",
    "    boots_idx = 0\n",
    "    X_te = pd.DataFrame(columns=X.columns)\n",
    "    y_te = pd.DataFrame(columns=y_df.columns)\n",
    "    X_tr = pd.DataFrame(columns=X.columns)\n",
    "    y_tr = pd.DataFrame(columns=y_df.columns)\n",
    "    done = False\n",
    "    while (done==False):\n",
    "        if (bootstrap_idx[boots_idx] != j):\n",
    "            df = X[j:j+1]\n",
    "            X_te = X_te.append(df, ignore_index=True)\n",
    "            df = y_df[j:j+1]\n",
    "            y_te = y_te.append(df, ignore_index=True)\n",
    "        else:\n",
    "            while (bootstrap_idx[boots_idx] == j):\n",
    "                df = X[j:j+1]\n",
    "                X_tr = X_tr.append(df, ignore_index=True)\n",
    "                df = y_df[j:j+1]\n",
    "                y_tr = y_tr.append(df, ignore_index=True)\n",
    "                boots_idx = boots_idx + 1   \n",
    "        j = j + 1\n",
    "        if (j==bootstrap_size):\n",
    "            done = True\n",
    "        if (boots_idx==bootstrap_size):\n",
    "            done = True\n",
    "\n",
    "    print(\"Fraction of instances in test data = \", len(y_te)/len(y))  \n",
    "                \n",
    "    # fit model and make predictions\n",
    "    y_tr = np.ravel(y_tr)\n",
    "    y_tr = y_tr.astype('int')\n",
    "    y_te = np.ravel(y_te)\n",
    "    y_te = y_te.astype('int')\n",
    "    lr = logres.fit(X_tr, y_tr)\n",
    "    \n",
    "    y_tr_pred = lr.predict(X_tr)\n",
    "    y_te_pred = lr.predict(X_te)\n",
    "    \n",
    "    # compute bootstrap accuracy\n",
    "    te_acc = 0\n",
    "    j = 0\n",
    "    while (j < len(y_te)):\n",
    "        if (y_te[j] == y_te_pred[j]):\n",
    "            te_acc = te_acc + 1\n",
    "        j = j + 1\n",
    "    \n",
    "    tr_acc = 0\n",
    "    j = 0\n",
    "    while (j < len(y_tr)):\n",
    "        if (y_tr[j] == y_tr_pred[j]):\n",
    "            tr_acc = tr_acc + 1\n",
    "        j = j + 1\n",
    "    \n",
    "    te_acc = te_acc/len(y_te)\n",
    "    tr_acc = tr_acc/len(y_tr)\n",
    "    acc = acc + (.632*te_acc) + (.368*tr_acc)\n",
    "    \n",
    "    i = i + 1  \n",
    "  \n",
    "acc = acc/total_bootstraps\n",
    "print(\"BOOTSTRAP STATS\")\n",
    "print(\"Accuracy = \", acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10-fold cv: In the box below, I have include code to perform and report statistics for 10-fold cv. Review the code and add code to plot a stacked bargraph showing the distribution of class for each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spambase' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-dbed3dfc5df4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mX_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspambase\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mX_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'spam_class'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spambase' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "k = 10\n",
    "\n",
    "X_df = spambase\n",
    "X_df = X_df.drop('spam_class', axis=1)\n",
    "\n",
    "X = np.ravel(X_df).reshape(4601, 58)\n",
    "\n",
    "# Set y as the spam column, we need to wrap it in the dataframe to stop it being series \n",
    "y_df = pd.DataFrame(spambase.spam_class)\n",
    "\n",
    "# flatten y into a 1-D array\n",
    "y = np.ravel(y_df)\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=None)\n",
    "\n",
    "tp = 0\n",
    "fp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "\n",
    "spam_bar = []\n",
    "non_spam_bar = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_tr, X_te = X[train_index], X[test_index]\n",
    "    y_tr, y_te = y[train_index], y[test_index]\n",
    "    lr = logres.fit(X_tr, y_tr)\n",
    "    y_te_pred = lr.predict(X_te)\n",
    " \n",
    "    # compute confusion matrix statistics\n",
    "    j = 0\n",
    "    while (j < len(y_te)):\n",
    "        if (y_te_pred[j]==y_te[j]):\n",
    "            if (y_te[j]==0): # tn\n",
    "                tn = tn + 1\n",
    "            else: # tp\n",
    "                tp = tp + 1\n",
    "        else:\n",
    "            if (y_te[j]==0): # fp\n",
    "                fp = fp + 1\n",
    "            else: # fn\n",
    "                fn = fn + 1        \n",
    "        j = j + 1\n",
    "     \n",
    "    total = y_te.size    \n",
    "    non_zero=np.count_nonzero(y_te)    \n",
    "    zero = total - non_zero\n",
    "\n",
    "    spam_num = non_zero/total\n",
    "    not_spam = zero/total\n",
    "    spam_bar.append(spam_num)\n",
    "    non_spam_bar.append(not_spam)\n",
    "   \n",
    "    \n",
    "    \n",
    "acc = (tp+tn)/len(y)\n",
    "tpr = tp/(tp+fn)\n",
    "fpr = fp/(fp+tn)\n",
    "\n",
    "print(\"Acc, TPR, FPR = \", acc, tpr, fpr)\n",
    "print (spam_bar,'\\n', non_spam_bar)\n",
    "\n",
    "# Add code for the plotting of stacked bar graph show distribution of classes for each fold\n",
    "\n",
    "\n",
    "# non_zero=np.count_nonzero(y_te)\n",
    "\n",
    "# total = y_te.size\n",
    "# zero = total - non_zero\n",
    "\n",
    "# spam_num = non_zero/total\n",
    "# not_spam = zero/total\n",
    "\n",
    "# spam_num = np.array(spam_num)\n",
    "# not_spam = np.array(not_spam)\n",
    "# print (non_zero, zero, spam_num, not_spam)\n",
    "\n",
    "N = 10\n",
    "ind = np.arange(N)    # the x locations for the groups\n",
    "width = 0.35       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "p1 = plt.bar(ind, spam_bar, width)\n",
    "p2 = plt.bar(ind, non_spam_bar, width, bottom=spam_bar)\n",
    "\n",
    "plt.legend((p1[0],p2[1]),('Spam','Not Spam'),loc='lower right')\n",
    "plt.xlabel('Folds')\n",
    "plt.title('Class Distribution by Fold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified 10-fold cv:  In the box below, write code that performs stratified 10-fold cv and print the final performance statistics (acc, tpr, fpr). Include the code for the stacked bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc, TPR, FPR =  0.9265377091936535 0.8885824600110315 0.04878048780487805\n",
      "[0.3947939262472885, 0.3947939262472885, 0.3947939262472885, 0.3934782608695652, 0.3934782608695652, 0.3934782608695652, 0.3934782608695652, 0.3934782608695652, 0.39433551198257083, 0.39433551198257083] \n",
      " [0.6052060737527115, 0.6052060737527115, 0.6052060737527115, 0.6065217391304348, 0.6065217391304348, 0.6065217391304348, 0.6065217391304348, 0.6065217391304348, 0.6056644880174292, 0.6056644880174292]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEWCAYAAACdaNcBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAG41JREFUeJzt3XuYVNWd7vHvS4OAAQWBRKFVUNEMDmIyeCFegqIJmATM\niY4gatAYYo6gQSfGZBxCJmYejYl6jBqGGLzFCydeEBQVo2GUowQwKogMCQJiIyoiCN646O/8URum\nKLup6qa6C1e/n+fp56m916q9f7Vp3t619q5VigjMzCwtLSpdgJmZlZ/D3cwsQQ53M7MEOdzNzBLk\ncDczS5DD3cwsQQ53A0DSOEl/qHQd+SQ9LOnbZdrWMZIW5S0vk3RCObadbW+BpP7l2l7edmdIOrfc\n263H/rtLCkkt62jf6X5vLMfh3oxIOl3SXEnvSlqZhefRFaolJL2X1bJa0uOSTsvvExGDIuLWErd1\nwPb6RMRTEXHQjtad7e8WSZcXbP/giJhRju03hryQfjfv54VK12WNx+HeTEi6CLgW+A/gc8A+wA3A\n4AqW1Sci2gEHAbcA10v6abl3UtdZZzPVISLaZT99Kl2MNR6HezMgaXfg34HzI+K+iHgvIjZFxIMR\ncUkdz/mjpNclvSPpSUkH57WdJOklSeslrZD0L9n6zpIelLRW0tuSnpJU9HcsIt6KiNuB7wM/ltQp\n297WIQlJB0j6r6yetyRNytY/mW3mhexs9DRJ/SXVSPqRpNeBm7esK9j1YdnrWCPpZkltsm2OkDSz\n4HhEVsNIYDhwSba/qVn71mEeSa0lXSvpteznWkmts7YttV0s6c3sHdTZRQ7R/pJmS1on6QFJe2Tb\nekjS6II650n6ZrFjXvCcFpIuk/RKVtNt2e9MbX17ZP8O6yU9BnSuz76s6Tjcm4d+QBvg/no852Gg\nJ/BZ4K/AHXltvwe+FxHtgX8EnsjWXwzUAF3IvTv4CVCf+S0eAFoCh9fS9nNgOtARqAZ+AxARx2bt\nfbKz0UnZ8p7AHsC+wMg69jcc+CqwP3AgcFmxAiNiArlj8ctsf9+opdu/AkcChwJ9steTv+09gd2B\nbsB3gBskddzObs8CzgH2AjYD12XrbwXO2NJJUp9smw8Vex0FRmQ/xwH7Ae2A6+voeyfwLLlQ/zlQ\nlmsiVn4O9+ahE/BWRGwu9QkRMTEi1kfEBmAc0CfvbG4T0EvSbhGxJiL+mrd+L2Df7J3BU1GPyYsi\nYhPwFrlQLrSJXFB3jYgPI2JmLX3yfQz8NCI2RMQHdfS5PiJejYi3gV8Aw0qttYjhwL9HxJsRsQr4\nGXBmXvumrH1TREwD3iU3NFWX2yPixYh4D/g34J8lVQFTgAMl9cz6nQlMioiN29nWW9k7q7Vb3nFl\n9V4dEUsi4l3gx8DQwuEsSfsAhwH/lh3XJ4GpxQ+HVYLDvXlYDXQudexZUpWkKyS9LGkdsCxr2vIW\n/FvAScAr2Vv0ftn6q4DFwHRJSyRdWp8iJbUid9b/di3NlwACZit3Z8o5RTa3KiI+LNLn1bzHrwBd\nSy52+7pm26tr26sL/tC+T+5suS6FdbYCOmevbxJwRjb8NQy4vUhtnSOiQ/bzq+3U25Lcu698XYE1\n2R+Z/L62E3K4Nw/PABuAk0vsfzowBDiB3PBB92y9ACJiTkQMITdkMxn4v9n69RFxcUTsR+5C7UWS\nBtSjziHkhh1mFzZExOsR8d2I6Ap8D7ixyB0ypbxj2Dvv8T7Aa9nj94BdtzRI2rOe236N3LuM2rbd\nEIV1bnmHA7mhmeHAAOD9iHimAduvrd7NwBsF/VYCHSV9pqCv7YQc7s1ARLwDjCU3tnuypF0ltZI0\nSNIva3lKe3J/DFaTC7n/2NIgaRdJwyXtng2jrCM3BIKkr2cXHQW8A3y0pW17JO0haTi5u3eujIjV\ntfQ5VVJ1triGXMBu2fYb5MaK6+t8SdXZBcp/JXcWDPACcLCkQ7OLrOMKnldsf3cBl0nqIqkzuWO/\nI/eCnyGpl6RdyV0YvyciPgLIwvxj4NcUP2vfXr1jsoul7cj9e08qHMaLiFeAucDPst+Do4HarjnY\nTsDh3kxExK+Bi8hd2FtF7q3+KHJn3oVuI/d2ewXwEjCroP1MYFk2ZHMeuTNHyF2A/RO5MeRngBsj\n4s/bKesFSe+SG8o5FxgTEWPr6HsY8Jes/xTgwohYkrWNA27NxpH/eTv7K3QnuYu0S4CXgcsBIuJv\n5EL0T8DfgcLx/d+Tu+awVlJtx+9yciE4D5hP7oL05bX0K9Xt5G4VfZ3chfELCtpvA3rT8D8gE7N9\nPAksBT4ERtfR93TgCHJDZz/N9m07IfnLOsw+3SSdBYyMiIp8IM12Tj5zN/sUy4Zq/jcwodK12M7F\n4W72KSXpq+SG2N4gN8RktpWHZczMEuQzdzOzBFVsQqXOnTtH9+7dK7V7M7NPpWefffatiOhSrF/F\nwr179+7MnTu3Urs3M/tUklTSp4I9LGNmliCHu5lZghzuZmYJcribmSXI4W5mliCHu5lZgoqGu6SJ\n2fcqvlhHuyRdJ2lx9v2NXyx/mWZmVh+lnLnfAgzcTvsgclO99iT3XZW/3fGyzMxsR5TyzfRPUvvX\nnm0xBLgtcmYBHSTtVa4Czcys/srxCdVubPsdjzXZupWFHSWNJPsm+n322YFv5xq3e/E+2/R/p+H7\nKkcNjbH/naGGSu9/Z6jBv4s+BvXdf2PVUKBJL6hGxISI6BsRfbt0KTo1gpmZNVA5wn0F236Bb3W2\nzszMKqQc4T4FOCu7a+ZI4J2I+MSQjJmZNZ2iY+6S7gL6A50l1ZD7UtxWABExHpgGnETuS47fB85u\nrGLNzKw0RcM9IoYVaQ/g/LJVZGZmO8yfUDUzS5DD3cwsQQ53M7MEOdzNzBLkcDczS5DD3cwsQQ53\nM7MEOdzNzBLkcDczS5DD3cwsQQ53M7MEOdzNzBLkcDczS5DD3cwsQQ53M7MEOdzNzBLkcDczS5DD\n3cwsQQ53M7MEOdzNzBLkcDczS5DD3cwsQQ53M7MEOdzNzBLkcDczS5DD3cwsQQ53M7MEOdzNzBLk\ncDczS5DD3cwsQQ53M7MEOdzNzBJUUrhLGihpkaTFki6tpX13SVMlvSBpgaSzy1+qmZmVqmi4S6oC\nbgAGAb2AYZJ6FXQ7H3gpIvoA/YFfS9qlzLWamVmJSjlzPxxYHBFLImIjcDcwpKBPAO0lCWgHvA1s\nLmulZmZWslLCvRvwat5yTbYu3/XAPwCvAfOBCyPi48INSRopaa6kuatWrWpgyWZmVky5Lqh+FXge\n6AocClwvabfCThExISL6RkTfLl26lGnXZmZWqJRwXwHsnbdcna3LdzZwX+QsBpYCny9PiWZmVl+l\nhPscoKekHtlF0qHAlII+y4EBAJI+BxwELClnoWZmVrqWxTpExGZJo4BHgSpgYkQskHRe1j4e+Dlw\ni6T5gIAfRcRbjVi3mZltR9FwB4iIacC0gnXj8x6/BnylvKWZmVlD+ROqZmYJcribmSXI4W5mliCH\nu5lZghzuZmYJcribmSXI4W5mliCHu5lZghzuZmYJcribmSXI4W5mliCHu5lZghzuZmYJcribmSXI\n4W5mliCHu5lZghzuZmYJcribmSXI4W5mliCHu5lZghzuZmYJcribmSXI4W5mliCHu5lZghzuZmYJ\ncribmSXI4W5mliCHu5lZghzuZmYJcribmSXI4W5mliCHu5lZgkoKd0kDJS2StFjSpXX06S/peUkL\nJP1Xecs0M7P6aFmsg6Qq4AbgRKAGmCNpSkS8lNenA3AjMDAilkv6bGMVbGZmxZVy5n44sDgilkTE\nRuBuYEhBn9OB+yJiOUBEvFneMs3MrD5KCfduwKt5yzXZunwHAh0lzZD0rKSzylWgmZnVX9FhmXps\n55+AAUBb4BlJsyLib/mdJI0ERgLss88+Zdq1mZkVKuXMfQWwd95ydbYuXw3waES8FxFvAU8CfQo3\nFBETIqJvRPTt0qVLQ2s2M7MiSgn3OUBPST0k7QIMBaYU9HkAOFpSS0m7AkcAC8tbqpmZlarosExE\nbJY0CngUqAImRsQCSedl7eMjYqGkR4B5wMfATRHxYmMWbmZmdStpzD0ipgHTCtaNL1i+CriqfKWZ\nmVlD+ROqZmYJcribmSXI4W5mliCHu5lZghzuZmYJcribmSXI4W5mliCHu5lZghzuZmYJcribmSXI\n4W5mliCHu5lZghzuZmYJcribmSXI4W5mliCHu5lZghzuZmYJcribmSXI4W5mliCHu5lZghzuZmYJ\ncribmSXI4W5mliCHu5lZghzuZmYJcribmSXI4W5mliCHu5lZghzuZmYJcribmSXI4W5mliCHu5lZ\nghzuZmYJKincJQ2UtEjSYkmXbqffYZI2SzqlfCWamVl9FQ13SVXADcAgoBcwTFKvOvpdCUwvd5Fm\nZlY/pZy5Hw4sjoglEbERuBsYUku/0cC9wJtlrM/MzBqglHDvBryat1yTrdtKUjfgm8Bvt7chSSMl\nzZU0d9WqVfWt1czMStSyTNu5FvhRRHwsqc5OETEBmADQt2/faOjOun94Z736L2vojspUQ2Psf2eo\nodL73xlq8O+ij0F9999YNRQqJdxXAHvnLVdn6/L1Be7Ogr0zcJKkzRExuSxVmplZvZQS7nOAnpJ6\nkAv1ocDp+R0ioseWx5JuAR50sJuZVU7RcI+IzZJGAY8CVcDEiFgg6bysfXwj12hmZvVU0ph7REwD\nphWsqzXUI2LEjpdlZmY7wp9QNTNLkMPdzCxBDnczswQ53M3MEuRwNzNLkMPdzCxBDnczswQ53M3M\nEuRwNzNLkMPdzCxBDnczswQ53M3MEuRwNzNLkMPdzCxBDnczswQ53M3MEuRwNzNLkMPdzCxBDncz\nswQ53M3MEuRwNzNLkMPdzCxBDnczswQ53M3MEuRwNzNLkMPdzCxBDnczswQ53M3MEuRwNzNLkMPd\nzCxBDnczswQ53M3MElRSuEsaKGmRpMWSLq2lfbikeZLmS3paUp/yl2pmZqUqGu6SqoAbgEFAL2CY\npF4F3ZYCX46I3sDPgQnlLtTMzEpXypn74cDiiFgSERuBu4Eh+R0i4umIWJMtzgKqy1ummZnVRynh\n3g14NW+5JltXl+8AD9fWIGmkpLmS5q5atar0Ks3MrF7KekFV0nHkwv1HtbVHxISI6BsRfbt06VLO\nXZuZWZ6WJfRZAeydt1ydrduGpEOAm4BBEbG6POWZmVlDlHLmPgfoKamHpF2AocCU/A6S9gHuA86M\niL+Vv0wzM6uPomfuEbFZ0ijgUaAKmBgRCySdl7WPB8YCnYAbJQFsjoi+jVe2me1sdmvdgtFHdGTf\nDq0QqrPfwoULy77v3w3eq+S+ld5/qTW0adOG6upqWrVq1aCaShmWISKmAdMK1o3Pe3wucG6DKjCz\nJIw+oiNf3L8rLXdtT3aSV6t/qO5Q9n1vqllbct9K77+UGiKC1atXU1NTQ48ePRpUkz+hamZlsW+H\nVkWD3UojiU6dOvHhhx82eBsOdzMrCyEHexnt6LF0uJuZJaikMXczs/oafP3/K+v2ll3xtZL6/e66\nXzHtgXupatGCFi1acNkV13DIF5rf/R0OdzNLxgvPzubJx6czadoMdmndmjVvr2bTxo2VLqsiHO5m\nloxVb75Bhz32YJfWrQHouEcnAAb1O4SvfP1kZv75T3TcrR133nknBxxwAFOnTuXyyy9n48aNdOrU\niTvuuIPPfe5zjBs3jqVLl7JkyRKWL1/ONddcw6xZs3j44Yfp1q0bU6dObfAtik3FY+5mlowvHXsc\nb7y2gm8c25df/ORi5j7zP0ND7drvxr1/eppRo0bxgx/8AICjjz6aWbNm8dxzzzF06FB++ctfbu3/\n8ssv88QTTzBlyhTOOOMMjjvuOObPn0/btm156KGHmvy11ZfP3M0sGbt+ph13TZvBX2c/w5ynn+KS\n88/hwkt/CsCgIacAMGzYMMaMGQNATU0Np512GitXrmTjxo3b3FM+aNAgWrVqRe/evfnoo48YOHAg\nAL1792bZsmVN+8IawOFuZkmpqqrisH5Hc1i/o+n5+V5MueeuXEPerYVbbjMcPXo0F110EYMHD2bG\njBmMGzdua5/W2dBOixYtaNWq1dbntGjRgs2bNzfNi9kBHpYxs2Qse/nvvLL05a3LixbMZ69uuXkP\nH516HwCTJk2iX79+ALzzzjt065abwfzWW29t4mobl8/czaxRTBl1VK3rD2mEj/9v8f5773HF2EtY\nv24dVVVV7N19P8ZeeS1PPf4o695ZyyknHsXu7XblrrtyZ/Pjxo3j1FNPpWPHjhx//PEsXbq00Wpr\nag53M0tGr0MO5bbJ02ttG3HeBYz5yc+2+eMyZMgQhgwZ8om++cMzAO+++26dbTsrD8uYmSXIZ+5m\nlryHn5lX6RKanM/czcwS5HA3M0uQw93MLEEOdzOzBPmCqpk1ikNu2re8Gxz3TtEuffbuyJnfPZ9/\nGXs5ALeO/w3vv/8e37/o0jqfM3nyZA488EB69er1ibZFixbxve99j7Vr17JhwwaOOeYYJkyY0PDX\n0IR85m5mydildWsef2Qqa95eXfJzJk+ezEsvvVRr2wUXXMCYMWN4/vnnWbhwIaNHjy5XqY3O4W5m\nyaiqaskpp3+bP/zuxk+0rXh1OeeeNphDDjmEAQMGsHz5cp5++mmmTJnCD3/4Qw499FBefvnlbZ6z\ncuVKqqurty737t0bgFtuuYUhQ4bQv39/evbsyfhrrtza5wffGc7Qk/rzzQH9uOeOW7auP/Kgaq6+\n/N/45oB+nHDCCcyePZv+/fuz3377MWXKlPIeCBzuZpaY0759LtMm/5H167Ydxrli7CUMPmUY8+bN\nY/jw4VxwwQV86UtfYvDgwVx11VU8//zz7L///ts8Z8yYMRx//PEMGjSIa665hrVr125tmz17Nvfe\ney/z5s1j+oOTWfDCcwD87FfXc/e0Gdz14BPcOfE/WbvmbQA+eP89Dj/qWO5//Bnat2/PZZddxmOP\nPcb999/P2LFjy34cHO5mlpR27Xfj698ayp0Ttx0bn/fsHAadnJv298wzz2TmzJlFt3X22WezcOFC\nTj31VGbMmMGRRx7Jhg0bADjxxBPp1KkTbdu2ZcCgb/DcnFkA3Hnzf3LqV47mzCEn8sbKFSzPJjJr\ntcsuHNX/BCD3DuDLX/7y1imFG2MKYYe7mSXnjO98n8mTbueDD97f4W117dqVc845hwceeICWLVvy\n4osvAv8zbfAWkpjzzExmzZzBbQ9M54/TZ/L5gw/Z+segZcttpw3On1K4MaYQdribWXJ279iRr3z9\nZO6/+/at6/r80+E8MuVeAO644w6OOeYYANq3b8/69etr3c4jjzzCpk2bAHj99ddZvXr11imCH3vs\nMd5++20++OAD/vzoQxza9wjeXbeO3XbvQNu2u7J08d+Y99zcxnyZ2+VbIc2sUcw795Va1zfmlL/5\nzho5irtvuWnr8qU/v5KxF49i0u9vpEuXLtx8880ADB06lO9+97tcd9113HPPPduMu0+fPp0LL7yQ\nNm3aAHDVVVex5557AnD44YfzrW99i5qaGk4cfAoH9/kCPT/fiz/+YSInH3cE3fc7gEO+0LdJXmtt\nHO5mloxZi2q2Pu7U5bP85e+vbV3uWr0PN02a8ok/LkcddVSdt0JeffXVXH311bW2VVdXM3nyZADm\n1eQutO7SujU33n5P0dq2N6VwuXhYxswsQT5zNzOrpxEjRjBixIhKl7FdPnM3s7IIgoiodBnJ2NFj\n6XA3s7J4Ze0mNr+/zgFfBhHB6tWrt17IbQgPy5hZWfzmL2sYDezb4S2E6uy3cH3bsu/7jTUflNy3\n0vsvtYY2bdpsM/VBfTnczaws1m34mF88WXzCrmVXfK3s+x506UMl9630/hurhkIlDctIGihpkaTF\nkj4xd6Zyrsva50n6YvlLNTOzUhUNd0lVwA3AIKAXMExS4cTHg4Ce2c9I4LdlrtPMzOqhlDP3w4HF\nEbEkIjYCdwNDCvoMAW6LnFlAB0l7lblWMzMrkYpd2ZZ0CjAwIs7Nls8EjoiIUXl9HgSuiIiZ2fLj\nwI8iYm7BtkaSO7MHOAhYVK4XkukMvFXmbX7a+Bj4GICPwRYpHod9I6JLsU5NekE1IiYAjfYdVZLm\nRkTlJnPYCfgY+BiAj8EWzfk4lDIsswLYO2+5OltX3z5mZtZESgn3OUBPST0k7QIMBQq/E2oKcFZ2\n18yRwDsRsbLMtZqZWYmKDstExGZJo4BHgSpgYkQskHRe1j4emAacBCwG3gfObrySt+vT8bXkjcvH\nwMcAfAy2aLbHoegFVTMz+/Tx3DJmZglyuJuZJSiZcC82RULqJO0t6c+SXpK0QNKFla6pUiRVSXou\n+/xFsyOpg6R7JP23pIWS+lW6pqYmaUz2/+BFSXdJavj0ip9SSYR7iVMkpG4zcHFE9AKOBM5vhsdg\niwuBhZUuooL+D/BIRHwe6EMzOxaSugEXAH0j4h/J3QgytLJVNb0kwp3SpkhIWkSsjIi/Zo/Xk/sP\n3a2yVTU9SdXA14CbivVNkaTdgWOB3wNExMaIWFvZqiqiJdBWUktgV+C1Iv2Tk0q4dwNezVuuoRkG\n2xaSugNfAP5S2Uoq4lrgEuDjShdSIT2AVcDN2dDUTZI+U+mimlJErAB+BSwHVpL73M30ylbV9FIJ\nd8tIagfcC/wgItZVup6mJOnrwJsR8Wyla6mglsAXgd9GxBeA94BmdQ1KUkdy79x7AF2Bz0g6o7JV\nNb1Uwt3THwCSWpEL9jsi4r5K11MBRwGDJS0jNzR3vKQ/VLakJlcD1ETElndt95AL++bkBGBpRKyK\niE3AfcCXKlxTk0sl3EuZIiFpkkRunHVhRFxd6XoqISJ+HBHVEdGd3O/AExHRrM7YIuJ14FVJB2Wr\nBgAvVbCkSlgOHClp1+z/xQCa2UVlSORr9uqaIqHCZTW1o4AzgfmSns/W/SQiplWwJquM0cAd2YnO\nEio3HUhFRMRfJN0D/JXcXWTP0QynIfD0A2ZmCUplWMbMzPI43M3MEuRwNzNLkMPdzCxBDnczswQ5\n3C15kj6S9HzeT/ft9O1f12ySkpZJ6txYdZqVUxL3uZsV8UFEHFrpIsyaks/crVmS1EbSzZLmZxNs\nHVdLn06Spmfzgt8EKFv/GUkPSXohmy/8tCZ/AWZFONytOWibNyRzf7bufCAiojcwDLi1li90+Ckw\nMyIOBu4H9snWDwRei4g+2XzhjzTBazCrFw/LWHNQ27DM0cBvACLivyW9AhxY0OdY4H9lfR6StCZb\nPx/4taQrgQcj4qnGK92sYXzmblZPEfE3cjMtzgculzS2wiWZfYLD3Zqrp4DhAJIOJDfksqigz5PA\n6VmfQUDH7HFX4P2I+ANwFc1vSl37FPCwjDVXNwK/lTSf3MyBIyJiQ26G2K1+BtwlaQHwNLmpZAF6\nA1dJ+hjYBHy/6co2K41nhTQzS5CHZczMEuRwNzNLkMPdzCxBDnczswQ53M3MEuRwNzNLkMPdzCxB\n/x8p2RZHS1KrAQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21107581940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "\n",
    "k = 10\n",
    "\n",
    "X_df = spambase\n",
    "X_df = X_df.drop('spam_class', axis=1)\n",
    "\n",
    "X = np.ravel(X_df).reshape(4601, 58)\n",
    "\n",
    "# Set y as the spam column, we need to wrap it in the dataframe to stop it being series \n",
    "y_df = pd.DataFrame(spambase.spam_class)\n",
    "\n",
    "# flatten y into a 1-D array\n",
    "y = np.ravel(y_df)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=None)\n",
    "\n",
    "tp = 0\n",
    "fp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "\n",
    "spam_bar = []\n",
    "non_spam_bar = []\n",
    "\n",
    "# insert code here\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_tr, X_te = X[train_index], X[test_index]\n",
    "    y_tr, y_te = y[train_index], y[test_index]\n",
    "    lr = logres.fit(X_tr, y_tr)\n",
    "    y_te_pred = lr.predict(X_te)\n",
    " \n",
    "    # compute confusion matrix statistics\n",
    "    j = 0\n",
    "    while (j < len(y_te)):\n",
    "        if (y_te_pred[j]==y_te[j]):\n",
    "            if (y_te[j]==0): # tn\n",
    "                tn = tn + 1\n",
    "            else: # tp\n",
    "                tp = tp + 1\n",
    "        else:\n",
    "            if (y_te[j]==0): # fp\n",
    "                fp = fp + 1\n",
    "            else: # fn\n",
    "                fn = fn + 1        \n",
    "        j = j + 1\n",
    "     \n",
    "    total = y_te.size    \n",
    "    non_zero=np.count_nonzero(y_te)    \n",
    "    zero = total - non_zero\n",
    "\n",
    "    spam_num = non_zero/total\n",
    "    not_spam = zero/total\n",
    "    spam_bar.append(spam_num)\n",
    "    non_spam_bar.append(not_spam)\n",
    "   \n",
    "    \n",
    "    \n",
    "acc = (tp+tn)/len(y)\n",
    "tpr = tp/(tp+fn)\n",
    "fpr = fp/(fp+tn)\n",
    "\n",
    "print(\"Acc, TPR, FPR = \", acc, tpr, fpr)\n",
    "print (spam_bar,'\\n', non_spam_bar)\n",
    "\n",
    "# Add code for the plotting of stacked bar graph show distribution of classes for each fold\n",
    "\n",
    "\n",
    "# non_zero=np.count_nonzero(y_te)\n",
    "\n",
    "# total = y_te.size\n",
    "# zero = total - non_zero\n",
    "\n",
    "# spam_num = non_zero/total\n",
    "# not_spam = zero/total\n",
    "\n",
    "# spam_num = np.array(spam_num)\n",
    "# not_spam = np.array(not_spam)\n",
    "# print (non_zero, zero, spam_num, not_spam)\n",
    "\n",
    "N = 10\n",
    "ind = np.arange(N)    # the x locations for the groups\n",
    "width = 0.35       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "p1 = plt.bar(ind, spam_bar, width)\n",
    "p2 = plt.bar(ind, non_spam_bar, width, bottom=spam_bar)\n",
    "\n",
    "plt.legend((p1[0],p2[1]),('Spam','Not Spam'),loc='lower right')\n",
    "plt.xlabel('Folds')\n",
    "plt.title('Class Distribution by Fold')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# include stacked bar graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loo cv: In the bow below, write code that performs leave-one-out cv and print the final performance statistics (acc, tpr, fpr)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc, TPR, FPR =  0.927841773527494 0.8885824600110315 0.046628407460545196\n"
     ]
    }
   ],
   "source": [
    "# insert code here\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "k = 10\n",
    "\n",
    "X_df = spambase\n",
    "X_df = X_df.drop('spam_class', axis=1)\n",
    "\n",
    "X = np.ravel(X_df).reshape(4601, 58)\n",
    "\n",
    "# Set y as the spam column, we need to wrap it in the dataframe to stop it being series \n",
    "y_df = pd.DataFrame(spambase.spam_class)\n",
    "\n",
    "# flatten y into a 1-D array\n",
    "y = np.ravel(y_df)\n",
    "\n",
    "loo_cv = LeaveOneOut()\n",
    "# skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=None)\n",
    "\n",
    "tp = 0\n",
    "fp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "\n",
    "# spam_bar = []\n",
    "# non_spam_bar = []\n",
    "\n",
    "# insert code here\n",
    "for train_index, test_index in loo_cv.split(X):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_tr, X_te = X[train_index], X[test_index]\n",
    "    y_tr, y_te = y[train_index], y[test_index]\n",
    "    lr = logres.fit(X_tr, y_tr)\n",
    "    y_te_pred = lr.predict(X_te)\n",
    " \n",
    "    # compute confusion matrix statistics\n",
    "    j = 0\n",
    "    while (j < len(y_te)):\n",
    "        if (y_te_pred[j]==y_te[j]):\n",
    "            if (y_te[j]==0): # tn\n",
    "                tn = tn + 1\n",
    "            else: # tp\n",
    "                tp = tp + 1\n",
    "        else:\n",
    "            if (y_te[j]==0): # fp\n",
    "                fp = fp + 1\n",
    "            else: # fn\n",
    "                fn = fn + 1        \n",
    "        j = j + 1\n",
    "  \n",
    "    \n",
    "acc = (tp+tn)/len(y)\n",
    "tpr = tp/(tp+fn)\n",
    "fpr = fp/(fp+tn)\n",
    "\n",
    "print(\"Acc, TPR, FPR = \", acc, tpr, fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
