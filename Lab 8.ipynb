{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 8: Support Vector Machines and Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's start by loading the spambase data to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spambase loaded.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "spambase = pd.read_csv('spambase.csv')\n",
    "\n",
    "print(\"Spambase loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a support vectore classifier using the default kernel and C value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.833876221498\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.86      0.86       538\n",
      "          1       0.80      0.80      0.80       383\n",
      "\n",
      "avg / total       0.83      0.83      0.83       921\n",
      "\n",
      "[[463  75]\n",
      " [ 78 305]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# first we need to prepare the data\n",
    "\n",
    "# Copy spambase across and drop spam_class (we don't include the class feature in the training data)\n",
    "X = spambase\n",
    "X = X.drop('spam_class', axis=1)\n",
    "\n",
    "# Set y as the spam column, we need to wrap it in the dataframe to stop it being series \n",
    "y_df = pd.DataFrame(spambase.spam_class)\n",
    "\n",
    "# flatten y into a 1-D array\n",
    "y = np.ravel(y_df)\n",
    "\n",
    "# now split the data into training data and test data (80/20 split)\n",
    "# random_state = k sets a specific random seed\n",
    "# since random_state is fixed, this call will always produce the same split\n",
    "# if you leave out the random_state value, you will get a different random split when you run it agaimn\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "#cut and pste from here \n",
    "# create our model and fit it to our training data\n",
    "clf = svm.SVC(kernel='rbf',C=1) # defaults\n",
    "clf.fit(X_train, y_train) \n",
    "\n",
    "# make predictions on test data\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "# print accuracy\n",
    "print (np.mean(predicted == y_test)) \n",
    "\n",
    "# print precision and recall statistics\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "\n",
    "# print confusion matrix\n",
    "print(metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment with parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try out other kernels ('linear' 'poly' 'sigmoid') and other values for C\n",
    "# clf = svm.SVC(kernel='linear',C=3) # defaults\n",
    "# clf.fit(X_train, y_train) \n",
    "\n",
    "# # make predictions on test data\n",
    "# predicted = clf.predict(X_test)\n",
    "\n",
    "# # print accuracy\n",
    "# print (np.mean(predicted == y_test)) \n",
    "\n",
    "# # print precision and recall statistics\n",
    "# print(metrics.classification_report(y_test, predicted))\n",
    "\n",
    "# # print confusion matrix\n",
    "# print(metrics.confusion_matrix(y_test, predicted))\n",
    "\n",
    "\n",
    "clf = svm.SVC(kernel='poly',C=2) # defaults\n",
    "clf.fit(X_train, y_train) \n",
    "\n",
    "# make predictions on test data\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "# print accuracy\n",
    "print (np.mean(predicted == y_test)) \n",
    "\n",
    "# print precision and recall statistics\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "\n",
    "# print confusion matrix\n",
    "print(metrics.confusion_matrix(y_test, predicted))\n",
    "\n",
    "\n",
    "\n",
    "# clf = svm.SVC(kernel='sigmoid',C=3) # defaults\n",
    "# clf.fit(X_train, y_train) \n",
    "\n",
    "# # make predictions on test data\n",
    "# predicted = clf.predict(X_test)\n",
    "\n",
    "# # print accuracy\n",
    "# print (np.mean(predicted == y_test)) \n",
    "\n",
    "# # print precision and recall statistics\n",
    "# print(metrics.classification_report(y_test, predicted))\n",
    "\n",
    "# # print confusion matrix\n",
    "# print(metrics.confusion_matrix(y_test, predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use GridSearchCV to select parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'kernel': 'linear'} \n",
      "\n",
      "0.914223669924\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.93      0.93       538\n",
      "          1       0.91      0.89      0.90       383\n",
      "\n",
      "avg / total       0.91      0.91      0.91       921\n",
      "\n",
      "[[503  35]\n",
      " [ 44 339]]\n"
     ]
    }
   ],
   "source": [
    "# This takes a while to run.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "\n",
    "svc = svm.SVC()\n",
    "\n",
    "clf = GridSearchCV(svc, parameters, n_jobs=-1) # n_jobs -> number of parallel jobs\n",
    "                                               # -1 -> whatever the architecture allows\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.best_params_,\"\\n\")\n",
    "\n",
    "# make predictions on test data\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "# print accuracy\n",
    "print (np.mean(predicted == y_test)) \n",
    "\n",
    "# print precision and recall statistics\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "\n",
    "# print confusion matrix\n",
    "print(metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use the following documentation (and any other documentation you wish to use to implement a multi-class SVM using the data from last week's lab. Only, use the following four newsgroups (rather than all ten): 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey'\n",
    "\n",
    "http://scikit-learn.org/stable/modules/svm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey'] \n",
      "\n",
      "['rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey'] \n",
      "\n",
      "0 rec.autos\n",
      "2 rec.sport.hockey\n",
      "0 rec.autos\n",
      "0 rec.sport.baseball\n",
      "0 rec.sport.baseball\n",
      "0 rec.sport.baseball\n",
      "0 rec.sport.baseball\n",
      "0 rec.autos\n",
      "2 rec.sport.hockey\n",
      "3 rec.motorcycles\n",
      "3 rec.motorcycles\n",
      "0 rec.sport.baseball\n",
      "2 rec.sport.hockey\n",
      "0 rec.sport.baseball\n",
      "0 rec.autos\n",
      "0 rec.autos\n",
      "0 rec.autos\n",
      "0 rec.sport.baseball\n",
      "0 rec.sport.baseball\n",
      "2 rec.sport.hockey\n",
      "3 rec.motorcycles\n",
      "0 rec.autos\n",
      "0 rec.sport.baseball\n",
      "0 rec.autos\n",
      "0 rec.autos\n"
     ]
    }
   ],
   "source": [
    "# insert code here\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# load newsgroup train and test data\n",
    "# categories = ['rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey']\n",
    "\n",
    "categories = ['rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey']\n",
    "\n",
    "# read the data in twenty_train.data and twenty_train.target\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "# load the test data set and convert to word counts\n",
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# print the class names\n",
    "print (twenty_train.target_names, \"\\n\")\n",
    "print (twenty_test.target_names, \"\\n\")\n",
    "\n",
    "# print the class names for the first 25 articles\n",
    "for t in twenty_train.target[:25]:\n",
    "    print(twenty_train.target[t], twenty_train.target_names[t])\n",
    "    \n",
    "# print the first article\n",
    "# print(\"\\n\", twenty_train.data[:1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.969182389937\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "         rec.autos       0.96      0.98      0.97       396\n",
      "   rec.motorcycles       0.98      0.96      0.97       398\n",
      "rec.sport.baseball       0.97      0.95      0.96       397\n",
      "  rec.sport.hockey       0.97      0.98      0.98       399\n",
      "\n",
      "       avg / total       0.97      0.97      0.97      1590\n",
      "\n",
      "[[388   5   3   0]\n",
      " [ 14 382   2   0]\n",
      " [  3   2 379  13]\n",
      " [  1   1   5 392]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# transform data into to tfidf vectors\n",
    "\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data) \n",
    "# note that I am using .transform instead of .fit_transform. this keeps the columns the same as the training set\n",
    "X_test_counts = count_vect.transform(twenty_test.data)\n",
    "\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "# clf_2 = MultinomialNB().fit(X_train_tfidf, twenty_train.target)\n",
    "\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "\n",
    "X = X_train_tfidf\n",
    "y =  twenty_train.target\n",
    "\n",
    "lin_clf = svm.LinearSVC(multi_class='ovr')\n",
    "\n",
    "lin_clf.fit(X,y)\n",
    "# clf= svm.SVC(kernel='liner', decision_function_shape = 'ovo')\n",
    "# make predictions on test data\n",
    "predicted = lin_clf.predict(X_test_tfidf)\n",
    "\n",
    "# print accuracy\n",
    "print (np.mean(predicted == twenty_test.target)) \n",
    "\n",
    "# print precision and recall statistics\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))\n",
    "\n",
    "# print confusion matrix\n",
    "print(metrics.confusion_matrix(twenty_test.target, predicted))\n",
    "\n",
    "# fit and evaluate a multi-class svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
